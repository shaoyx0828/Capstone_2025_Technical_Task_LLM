# -*- coding: utf-8 -*-
"""
é«˜æ•ˆæ‰¹é‡æƒ…æ„Ÿåˆ†ç±» + è¯„ä¼°è„šæœ¬ï¼ˆä¼˜åŒ–ç‰ˆï¼Œæ”¯æŒ wandbï¼‰ï¼š
- ä½¿ç”¨ tokenizer + model æ¨ç†æ›¿ä»£ pipelineï¼ˆæ›´å¿«ï¼‰
- tqdm æ˜¾ç¤ºå®æ—¶è¿›åº¦æ¡
- æ”¯æŒ max_samples é™åˆ¶æ ·æœ¬æ•°
- æ”¶é›†å¹¶ä¿å­˜é”™è¯¯æ ·æœ¬
- è¾“å‡º wandb è®°å½•ï¼ˆå‡†ç¡®ç‡ / F1 / per-label åˆ†æ•°ï¼‰
"""

import json
import wandb
from pathlib import Path
from tqdm import tqdm
from sklearn.metrics import classification_report, accuracy_score
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# === åˆå§‹åŒ– wandb é¡¹ç›® ===
wandb.init(project="promptner-sentiment-eval", name="inference-eval-run")

# === åŠ è½½æ¨¡å‹ ===
model_path = "/media/mldadmin/home/s124mdg32_08/MotionBERT-main/LLM/model/qwen_sentiment_lora_finetuned"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForSequenceClassification.from_pretrained(
    model_path,
    num_labels=3,
    trust_remote_code=True,
    id2label={0: "positive", 1: "negative", 2: "neutral"},
    label2id={"positive": 0, "negative": 1, "neutral": 2}
).cuda().eval()

# === æ„é€ è¾“å…¥æ–‡æœ¬ ===
def build_sentiment_query(entity: str, context: str) -> str:
    return f"What is the sentiment toward \"{entity}\" in the following article?\n\n{context.strip()}"

# === ä¸»åˆ†ç±»æµç¨‹ï¼ˆæ”¯æŒ max_samplesï¼‰ ===
def batch_entity_sentiment_classify(input_path: str, output_path: str, error_path: str, max_samples: int = None):
    with open(input_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    if max_samples:
        data = data[:max_samples]

    output = []
    error_samples = []
    y_true, y_pred = [], []

    for entry in tqdm(data, desc="ğŸ” Predicting..."):
        text = entry.get("context", "")
        entity = entry.get("entity", "")
        label = entry.get("label", "")
        query = build_sentiment_query(entity, text)

        inputs = tokenizer(query, return_tensors="pt", truncation=True, max_length=512).to(model.device)
        with torch.no_grad():
            logits = model(**inputs).logits
            pred_id = logits.argmax(dim=-1).item()

        pred_label = model.config.id2label[pred_id]
        y_true.append(label)
        y_pred.append(pred_label)

        if pred_label != label:
            error_samples.append({"entity": entity, "context": text, "true": label, "pred": pred_label})

        output.append({
            "entity": entity,
            "context": text,
            "true_label": label,
            "predicted": pred_label,
            "score": round(torch.nn.functional.softmax(logits, dim=-1)[0][pred_id].item(), 4)
        })

    with open(output_path, "w", encoding="utf-8") as f:
        for item in output:
            json.dump(item, f, ensure_ascii=False)
            f.write("\n")

    with open(error_path, "w", encoding="utf-8") as f:
        for item in error_samples:
            json.dump(item, f, ensure_ascii=False)
            f.write("\n")

    print(f"âœ… Saved {len(output)} predictions â†’ {output_path}")
    print(f"âŒ Misclassified samples: {len(error_samples)} â†’ {error_path}")

    # === è¾“å‡ºè¯„ä¼° ===
    print("\nğŸ“Š Evaluation Report:")
    report = classification_report(y_true, y_pred, digits=4, output_dict=True)
    print(classification_report(y_true, y_pred, digits=4))
    acc = accuracy_score(y_true, y_pred)
    print(f"Accuracy: {acc:.4f}")

    # === wandb è®°å½• ===
    wandb.log({"accuracy": acc})
    for label in ["positive", "negative", "neutral"]:
        if label in report:
            wandb.log({
                f"precision_{label}": report[label]["precision"],
                f"recall_{label}": report[label]["recall"],
                f"f1_{label}": report[label]["f1-score"]
            })
    wandb.finish()

# === æ‰§è¡Œå…¥å£ ===
if __name__ == "__main__":
    input_json = "/media/mldadmin/home/s124mdg32_08/MotionBERT-main/LLM/rough_data/entity_sentiment_dataset.json"
    output_jsonl = "entity_sentiment_predictions.jsonl"
    error_output = "misclassified_samples.jsonl"

    # å¯é€‰ï¼šé™åˆ¶å¤„ç†æ•°é‡ï¼ˆåŠ é€Ÿæµ‹è¯•ï¼‰
    max_eval_samples = None  # æ”¹ä¸º 100 è¯•è¿è¡Œ

    batch_entity_sentiment_classify(input_json, output_jsonl, error_output, max_samples=max_eval_samples)
